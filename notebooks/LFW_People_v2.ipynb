{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312532b9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-17T16:46:40.890711Z",
     "end_time": "2023-05-17T16:46:46.743435Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,GlobalAveragePooling2D,Conv2D,MaxPooling2D,Activation,Dropout\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import FastGradientMethod, CarliniLInfMethod\n",
    "from art.attacks.evasion import FeatureAdversariesTensorFlowV2\n",
    "from art.estimators.classification import TensorFlowV2Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e793fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1140, 62, 47)\n",
      "(1140, 2914)\n",
      "(5,)\n",
      "(1140,)\n",
      "['Colin Powell' 'Donald Rumsfeld' 'George W Bush' 'Gerhard Schroeder'\n",
      " 'Tony Blair']\n",
      "5\n",
      "(1140, 62, 47)\n",
      "(1140, 62, 47, 1)\n",
      "(160, 62, 47, 1)\n",
      "(41, 62, 47, 1)\n",
      "(160, 5)\n",
      "(41, 5)\n"
     ]
    }
   ],
   "source": [
    "lfw_dataset=fetch_lfw_people(min_faces_per_person=100)\n",
    "\n",
    "print(lfw_dataset.images.shape)\n",
    "print(lfw_dataset.data.shape)\n",
    "print(lfw_dataset.target_names.shape)\n",
    "print(lfw_dataset.target.shape)\n",
    "\n",
    "lfw_dataset.target\n",
    "\n",
    "Name = lfw_dataset.target_names\n",
    "\n",
    "print(Name)\n",
    "print(len(Name))\n",
    "\n",
    "N=[]\n",
    "for i in range(len(Name)):\n",
    "    N+=[i]\n",
    "    \n",
    "mapping=dict(zip(Name,N)) \n",
    "reverse_mapping=dict(zip(N,Name)) \n",
    "\n",
    "def mapper(value):\n",
    "    return reverse_mapping[value]\n",
    "\n",
    "X0=lfw_dataset.images\n",
    "y=lfw_dataset.target\n",
    "\n",
    "print(X0.shape)\n",
    "X=X0.reshape(-1,62,47,1)\n",
    "print(X.shape)\n",
    "\n",
    "dataset=[]\n",
    "testset=[]\n",
    "t=0\n",
    "for Xi,yi in zip(X,y):\n",
    "    img=Xi/255.0\n",
    "    if t<=200:\n",
    "        dataset.append([img,yi])\n",
    "    else:   \n",
    "        testset.append([img,yi])\n",
    "    t+=1\n",
    "\n",
    "data,labels0=zip(*dataset)\n",
    "test,tlabels0=zip(*testset)\n",
    "\n",
    "labels1=to_categorical(labels0)\n",
    "data=np.array(data)\n",
    "labels=np.array(labels1)\n",
    "\n",
    "tlabels1=to_categorical(tlabels0)\n",
    "test=np.array(test)\n",
    "tlabels=np.array(tlabels1)\n",
    "\n",
    "# trainx,testx,trainy,testy=train_test_split(data,labels,test_size=0.2,random_state=44)\n",
    "trainx,testx,trainy,testy=train_test_split(data,labels,test_size=0.2,random_state=12)\n",
    "\n",
    "trainx = trainx.astype(np.float32)\n",
    "testx = testx.astype(np.float32)\n",
    "trainy = trainy.astype(np.float32)\n",
    "testy = testy.astype(np.float32)\n",
    "\n",
    "print(trainx.shape)\n",
    "print(testx.shape)\n",
    "print(trainy.shape)\n",
    "print(testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdfa17fa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-17T19:31:49.136284Z",
     "end_time": "2023-05-17T19:31:49.292978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 60, 45, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 30, 22, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 20, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 10, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4480)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               2294272   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,370,149\n",
      "Trainable params: 2,370,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=20,zoom_range=0.2,\n",
    "#                     width_shift_range=0.2,height_shift_range=0.2,shear_range=0.1,fill_mode=\"nearest\")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3), input_shape=(62,47,1), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1932c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# model.save(\"VGG_model_85.pth\")\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# !zip -r VGG_model_85.zip VGG_model_85.pth\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# model = keras.models.load_model(\"VGG_model_85.pth\")\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      6\u001B[0m \n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# his=model.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=1000)\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m his\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mfit(\u001B[43mtrainx\u001B[49m,trainy, validation_data\u001B[38;5;241m=\u001B[39m(testx,testy),epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trainx' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# model.save(\"VGG_model_85.pth\")\n",
    "# !zip -r VGG_model_85.zip VGG_model_85.pth\n",
    "# model = keras.models.load_model(\"VGG_model_85.pth\")\n",
    "\n",
    "## Training model\n",
    "\n",
    "# his=model.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=1000)\n",
    "his=model.fit(trainx,trainy, validation_data=(testx,testy),epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74cc18eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on benign test examples: 73.17073170731707%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 12:26:11.709716: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluate the ART classifier on benign test examples\n",
    "\n",
    "predictions = model.predict(testx)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(testy, axis=1)) / len(testy)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2982e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def train_step(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "classifier = TensorFlowV2Classifier(\n",
    "    model=model,\n",
    "    loss_object=loss_object,\n",
    "    train_step=train_step,\n",
    "    nb_classes=5,\n",
    "    input_shape=(62, 47, 1),\n",
    "    clip_values=(0, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc1c91e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41, 62, 47, 1), (160, 62, 47, 1), numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testx.shape, trainx.shape, type(testx), type(trainx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07edf0e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [37]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtestx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(np\u001B[38;5;241m.\u001B[39margmax(predictions, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(testy, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(testy)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy on benign test examples: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(accuracy \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m))\n",
      "File \u001B[0;32m~/miniforge3/envs/data-science/lib/python3.9/site-packages/art/estimators/classification/classifier.py:73\u001B[0m, in \u001B[0;36mInputFilter.__init__.<locals>.make_replacement.<locals>.replacement_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     72\u001B[0m     args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(lst)\n\u001B[0;32m---> 73\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfdict\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfunc_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/data-science/lib/python3.9/site-packages/art/estimators/classification/tensorflow.py:903\u001B[0m, in \u001B[0;36mTensorFlowV2Classifier.predict\u001B[0;34m(self, x, batch_size, training_mode, **kwargs)\u001B[0m\n\u001B[1;32m    894\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    895\u001B[0m \u001B[38;5;124;03mPerform prediction for a batch of inputs.\u001B[39;00m\n\u001B[1;32m    896\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;124;03m:return: Array of predictions of shape `(nb_inputs, nb_classes)`.\u001B[39;00m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;66;03m# Apply preprocessing\u001B[39;00m\n\u001B[0;32m--> 903\u001B[0m x_preprocessed, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_preprocessing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    905\u001B[0m \u001B[38;5;66;03m# Run prediction with batch processing\u001B[39;00m\n\u001B[1;32m    906\u001B[0m results_list \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/miniforge3/envs/data-science/lib/python3.9/site-packages/art/estimators/tensorflow.py:199\u001B[0m, in \u001B[0;36mTensorFlowV2Estimator._apply_preprocessing\u001B[0;34m(self, x, y, fit)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# Convert torch tensors back to np arrays.\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m input_is_tensor:\n\u001B[0;32m--> 199\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m()\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    201\u001B[0m         y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[0;32m~/miniforge3/envs/data-science/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:513\u001B[0m, in \u001B[0;36mTensor.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mT\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mravel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtranspose\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreshape\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclip\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msize\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    506\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtolist\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n\u001B[1;32m    507\u001B[0m   \u001B[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001B[39;00m\n\u001B[1;32m    508\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m    509\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001B[39m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;124m    from tensorflow.python.ops.numpy_ops import np_config\u001B[39m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;124m    np_config.enable_numpy_behavior()\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n\u001B[0;32m--> 513\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(testx)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(testy, axis=1)) / len(testy)\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: prepare a batch of source and guide images\n",
    "valid = np.argmax(testy, axis=1)[:20] != np.argmax(testy, axis=1)[20:40]\n",
    "source = testx[:20][valid][:32]\n",
    "guide = testx[20:40][valid][:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4929884",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.shape, source.shape, guide.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import FeatureAdversariesTensorFlowV2\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "\n",
    "# Step 6: Generate adversarial test examples\n",
    "attack = FeatureAdversariesTensorFlowV2(\n",
    "    classifier,\n",
    "    layer=-2,\n",
    "    delta=45/255,\n",
    "    optimizer=None,\n",
    "    step_size=1/255,\n",
    "    max_iter=100,\n",
    ")\n",
    "x_test_adv = attack.generate(source, guide)\n",
    "\n",
    "# Step 7: Evaluate the ART classifier on adversarial test examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9177a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(x_test_adv)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(testy[:20][valid][:32], axis=1)) / len(testy[:20][valid][:32])\n",
    "\n",
    "dim = tuple(range(1, len(source.shape)))\n",
    "pert = np.mean(np.amax(np.abs(source - x_test_adv), axis=dim))\n",
    "print(\"Accuracy on adversarial test batch: {}%\".format(accuracy * 100))\n",
    "print(\"Average perturbation: {}%\".format(pert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c03ed4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# eps = [1e-5, 1/255, 2/255, 3/255]\n",
    "eps = np.linspace(1e-3, 20/255, num=100)\n",
    "accuracyList = []\n",
    "for _eps in eps:\n",
    "    attack = FeatureAdversariesTensorFlowV2(\n",
    "        classifier,\n",
    "        layer=-2,\n",
    "        delta=_eps,\n",
    "        optimizer=None,\n",
    "        step_size=1/255,\n",
    "        max_iter=100,\n",
    "    )\n",
    "    x_test_adv = attack.generate(source, guide)\n",
    "    predictions = classifier.predict(x_test_adv)\n",
    "    accuracyList.append(np.sum(np.argmax(predictions, axis=1) == np.argmax(testy[:20][valid][:32], axis=1)) / len(testy[:20][valid][:32]))\n",
    "    print(\"finish with eps:\", _eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3beecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eps, accuracyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import TensorFlowV2Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e07e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7080112",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = FeatureAdversariesTensorFlowV2(\n",
    "        classifier,\n",
    "        layer=-2,\n",
    "        delta=45/255,\n",
    "        optimizer=tf.keras.optimizers.Adam,\n",
    "        optimizer_kwargs={\"learning_rate\": 0.01},\n",
    "        lambda_=1.0,\n",
    "        max_iter=100,\n",
    "        random_start=True,\n",
    ")\n",
    "\n",
    "# создаем атаку FGSM\n",
    "attack = FastGradientMethod(estimator=estimator, eps=0.1)\n",
    "\n",
    "# генерируем атакующий пример\n",
    "x_test_adv = attack.generate(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763dde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Inspect results\n",
    "\n",
    "# orig 7, guide 6\n",
    "plt.imshow(x_test_adv[3,...].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(testx[3,...].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cefb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gallery(images, titles, h=62, w=47, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i+1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(np.argmax(titles[i]), size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_test_adv).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery(testx, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003430a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery(x_test_adv, model.predict(x_test_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e309b9ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_gallery' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [38]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mplot_gallery\u001B[49m(testx, testy)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plot_gallery' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627c5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
